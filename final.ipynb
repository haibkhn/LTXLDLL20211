{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0dabd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "sc = SparkContext()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b4ab3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.options(header='True', inferSchema=True).csv('hdfs://hadoop-master:9000/preprocess_data_to_train_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "362ce491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: double (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- runtime: double (nullable = true)\n",
      " |-- kind: integer (nullable = true)\n",
      " |-- color_info: integer (nullable = true)\n",
      " |-- sound_mix: integer (nullable = true)\n",
      " |-- director_name: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- director_id: string (nullable = true)\n",
      " |-- cast_names: string (nullable = true)\n",
      " |-- cast_ids: string (nullable = true)\n",
      " |-- votes: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- number_cast: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3f456aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "data = data.withColumn(\"votes\", data[\"votes\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"country\", data[\"country\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"day\", data[\"day\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"month\", data[\"month\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"age\", data[\"age\"].cast(IntegerType()))\n",
    "data = data.withColumn(\"number_cast\", data[\"number_cast\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcecf7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: double (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- runtime: double (nullable = true)\n",
      " |-- kind: integer (nullable = true)\n",
      " |-- color_info: integer (nullable = true)\n",
      " |-- sound_mix: integer (nullable = true)\n",
      " |-- director_name: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- director_id: string (nullable = true)\n",
      " |-- cast_names: string (nullable = true)\n",
      " |-- cast_ids: string (nullable = true)\n",
      " |-- votes: integer (nullable = true)\n",
      " |-- country: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- number_cast: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da4912e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[title: string, year: double, rating: double, runtime: double, kind: int, color_info: int, sound_mix: int, director_name: string, genre: string, director_id: string, cast_names: string, cast_ids: string, votes: int, country: int, day: int, month: int, age: int, number_cast: int]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82a7b42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "vectorAssembler = VectorAssembler(inputCols = ['year', 'runtime', 'kind', 'color_info', 'sound_mix',\n",
    "       'votes', 'country', 'day', 'month', 'age', 'number_cast'], outputCol = 'features')\n",
    "movie_df = vectorAssembler.setHandleInvalid(\"skip\").transform(data)\n",
    "movie_df = movie_df.select(['features', 'rating'])\n",
    "# movie_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "194551ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = movie_df.randomSplit([0.7, 0.3])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2af069f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.00010049872996590219,0.0019438997220908706,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.00010049872997920101,0.0]\n",
      "Intercept: 5.951667884894286\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='rating', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lr_model = lr.fit(train_df)\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abf40c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.217123\n",
      "r2: 0.017396\n"
     ]
    }
   ],
   "source": [
    "trainingSummary = lr_model.summary\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33567a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+--------------------+\n",
      "|       prediction|rating|            features|\n",
      "+-----------------+------+--------------------+\n",
      "|5.851842617929861|   5.9|[1894.0,40.0,1.0,...|\n",
      "|5.907747640073246|   6.1|[1906.0,70.0,1.0,...|\n",
      "|6.011311242846537|   7.4|[1913.0,124.0,1.0...|\n",
      "|5.875037264840231|   6.4|[1914.0,54.0,1.0,...|\n",
      "|5.876981164562322|   5.8|[1914.0,55.0,1.0,...|\n",
      "+-----------------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "R Squared (R2) on test data = 0.0188672\n"
     ]
    }
   ],
   "source": [
    "lr_predictions = lr_model.transform(test_df)\n",
    "lr_predictions.select(\"prediction\",\"rating\",\"features\").show(5)\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"rating\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(lr_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89c4b010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 1.2127\n"
     ]
    }
   ],
   "source": [
    "test_result = lr_model.evaluate(test_df)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % test_result.rootMeanSquaredError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c330e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numIterations: 9\n",
      "objectiveHistory: [0.5, 0.49986712396105876, 0.49930976210576794, 0.499299483259487, 0.4992960925746888, 0.499296016806366, 0.49929601293854287, 0.4992960128340995, 0.4992960128307556, 0.49929601283065606]\n",
      "+--------------------+\n",
      "|           residuals|\n",
      "+--------------------+\n",
      "|0.026303642502024438|\n",
      "|-0.08710265809266637|\n",
      "|  0.4962633585818814|\n",
      "|  1.1247617376998242|\n",
      "|  1.1111544396451878|\n",
      "|  0.5645008463150072|\n",
      "|  0.5645008463150072|\n",
      "|  0.5645008463150072|\n",
      "| 0.05866914714873417|\n",
      "|  1.0547813477045525|\n",
      "|  1.0431179493720073|\n",
      "| -0.1789250642844129|\n",
      "|  -0.684756763450685|\n",
      "|  1.0152432365493151|\n",
      "| 0.21135543710513272|\n",
      "|-0.19253236233904847|\n",
      "| -0.5275225573366846|\n",
      "|  0.3705335429412244|\n",
      "|   0.232939331508077|\n",
      "|  0.6251637326197139|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aion_\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyspark\\sql\\context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"numIterations: %d\" % trainingSummary.totalIterations)\n",
    "print(\"objectiveHistory: %s\" % str(trainingSummary.objectiveHistory))\n",
    "trainingSummary.residuals.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4364079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------+--------------------+\n",
      "|        prediction|rating|            features|\n",
      "+------------------+------+--------------------+\n",
      "| 5.851842617929861|   5.9|[1894.0,40.0,1.0,...|\n",
      "| 5.907747640073246|   6.1|[1906.0,70.0,1.0,...|\n",
      "| 6.011311242846537|   7.4|[1913.0,124.0,1.0...|\n",
      "| 5.875037264840231|   6.4|[1914.0,54.0,1.0,...|\n",
      "| 5.876981164562322|   5.8|[1914.0,55.0,1.0,...|\n",
      "| 5.921690858170412|   6.4|[1914.0,78.0,1.0,...|\n",
      "| 5.933354256502957|   6.9|[1914.0,84.0,1.0,...|\n",
      "| 5.945017654835502|   6.3|[1914.0,90.0,1.0,...|\n",
      "| 5.859285069603559|   6.9|[1915.0,46.0,1.0,...|\n",
      "|  5.88455576599074|   6.0|[1915.0,59.0,1.0,...|\n",
      "|5.9098264623779215|   6.9|[1915.0,72.0,1.0,...|\n",
      "| 6.588247465387635|   7.3|[1915.0,421.0,1.0...|\n",
      "| 5.866859671031977|   6.4|[1916.0,50.0,1.0,...|\n",
      "| 5.866859671031977|   6.6|[1916.0,50.0,1.0,...|\n",
      "| 5.886298668252886|   6.9|[1916.0,60.0,1.0,...|\n",
      "| 6.037922846575974|   6.5|[1916.0,138.0,1.0...|\n",
      "| 5.870546473016214|   6.1|[1917.0,52.0,1.0,...|\n",
      "| 5.872490372738305|   6.0|[1917.0,53.0,1.0,...|\n",
      "| 5.876378172182487|   6.8|[1917.0,55.0,1.0,...|\n",
      "| 5.909424467458032|   6.4|[1917.0,72.0,1.0,...|\n",
      "+------------------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_model.transform(test_df)\n",
    "predictions.select(\"prediction\",\"rating\",\"features\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cbd9ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 1.05904\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "dt = DecisionTreeRegressor(featuresCol ='features', labelCol = 'rating')\n",
    "dt_model = dt.fit(train_df)\n",
    "dt_predictions = dt_model.transform(test_df)\n",
    "dt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"rating\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = dt_evaluator.evaluate(dt_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4828f7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(11, {0: 0.0383, 1: 0.3271, 3: 0.0886, 5: 0.2397, 6: 0.156, 9: 0.1402, 10: 0.01})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e309b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(features=DenseVector([1894.0, 40.0, 1.0, 0.0, 4.0, 191.0, 136.0, 0.0, 8.0, 127.0, 3.0]), rating=5.9)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.take(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c24ed40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------+--------------------+\n",
      "|        prediction|rating|            features|\n",
      "+------------------+------+--------------------+\n",
      "| 6.072570351339152|   5.9|[1894.0,40.0,1.0,...|\n",
      "| 6.653217690548708|   6.1|[1906.0,70.0,1.0,...|\n",
      "| 7.054937696948859|   7.4|[1913.0,124.0,1.0...|\n",
      "| 6.056904834370278|   6.4|[1914.0,54.0,1.0,...|\n",
      "|6.0366864610484186|   5.8|[1914.0,55.0,1.0,...|\n",
      "+------------------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "gbt = GBTRegressor(featuresCol = 'features', labelCol = 'rating', maxIter=10)\n",
    "gbt_model = gbt.fit(train_df)\n",
    "gbt_predictions = gbt_model.transform(test_df)\n",
    "gbt_predictions.select('prediction', 'rating', 'features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ad3fb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 1.03105\n"
     ]
    }
   ],
   "source": [
    "gbt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"rating\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = gbt_evaluator.evaluate(gbt_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
